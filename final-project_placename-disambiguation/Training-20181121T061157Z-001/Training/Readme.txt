This readme file describes in detail the corpus used for the SemEval 2018 Task 12 challenge, it is available from the google drive folder which is accessible by the link provided by the organizers.


1. Training corpus

The training corpus is composed of 105 articles which were randomly split into a development set and a validation set, 70-30% respectively, i.e. 73 and 32 articles. Each set is composed of two types of files, *.txt and  *.ann, for each article. 
- .txt files: are text files created using pdf-to-text to convert the original pdf articles.
- .ann file: are the offset annotations manually created using Brat.

During the training period the competitors will be able to train their system on the training set and submit their runs to codalab for evaluation on the validation set.


2. Description of annotation files

The annotation files contain 2 entity types of annotations indicated by two tags: Location and Protein, described in detail below.


a. The Location tag

Location tags are used to mark continuous spans of texts referring to the mentions of toponyms annotated. Considering the article PMC2816729 as an example, the PMC2816729.ann file contains the following lines: 

T47   Location 5046 5053   Bangkok
#47   AnnotatorNotes T47   <latlong>13.87719,100.71991</latlong><geoID>1609348</geoID><pop>5104476</pop>

In the first line, T47 is an ID generated automatically by Brat during the annotation. 'Location' is the tag defining the nature of the span of text annotated. 5046 5053 are the starting and ending positions of the annotation in the file PMC2816729.txt and these positions denote the sequence of character "Bangkok". In the second line, #47 is an ID generated by Brat for the note added to the annotation T47 by the annotators. The AnnotatorNotes for 'Location' contain at least two XML tags identified by <latlng> and <geoID>, the first tag gives the latitude and longitude of the location, the second tag its GeoNames ID. If the latitude, longitude and GeoNames ID could not been found by the Annotators the value NA is inserted in the tags. An additional XML tag can be found, <pop>, which describes the population of the place as listed in GeoNames. 

Note 1) the AnnotatorNotes ID is not necessarily equal to the annotation ID. In our example #47 is to T47 but it could have been #887 or any other number. 
Note 2) the AnnotatorNotes do not always follow in the lines immediately after the annotations they are linked to (that is other annotations could be found between a annotation and its AnnotatorNotes).


b. The Protein tag

The Protein tag is used to mark continuous spans of text that will be excluded from the evaluation, such spans are names of authors, reference, footnotes etc. They have been excluded from the annotations since they would not contain toponyms related to the biological content of the articles. Continuing with the article PMC2816729 as an example, the PMC2816729.ann file starts with the lines:

T1	Protein 0 8	American
#1	AnnotatorNotes T1	BEGIN
T2	Protein 559 571	Contribution
#2	AnnotatorNotes T2	END

The first and third lines are annotations and composed of similar components as the Location annotations: annotation IDs, the Protein Labels, positions and texts annotated. The second line is an AnnotatorsNotes which specifies the first token of the sequence of text excluded and the fourth line the AnnotatorsNotes specifying the last token. In our example, all tokens in the sequence “American Journal of […] Original Contribution” were excluded from the annotation process and any toponyms predicted by a system occurring within this sequence will be ignored during the evaluation of the system.

Note 3) the use of the word Protein as label is confusing but it is kept for compatibility with existing software making use of this corpus.
Note 4) all sequences denoted by the Protein annotation are continuous and the annotators made sure that the Protein annotations tagging the first tokens of the sequences excluded are immediately followed by the Protein annotations tagging the last tokens.


3. Test corpus

The test corpus is composed of 45 articles randomly selected using the same process when selecting the training corpus. 


a. Corpus for Tasks 1 and 3

For the task 1 and task 3, we will only release *.txt files and all competing systems will have to generate valid *.ann files where the starting and ending positions of the annotations predicted should STRICTLY correspond to the positions in the *.txt followed by the corresponding spans of text. 



b. Corpus for Task 2

For Task 2, the systems have to disambiguate the toponyms given. We will release the *.txt files used during Task 1 and 3 along with their *.ann files where both Protein and Location annotations are present but the AnnotatorNotes disambiguating the locations will be deleted. All competing systems will have to complete the *.ann files with the AnnotatorNotes following the same format, i.e: #ID AnnotatorNotes Location_Tag_ID <geoID>ID</geoID>. The XML tags <latlng> and <pop> are optional.



Any questions about the corpus or issues when running evaluations on codalab should be addressed to Davy Weissenbacher at: dweissen@pennmedicine.upenn.edu

